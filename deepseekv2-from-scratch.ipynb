{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepseekv2 implemented from scratch\n",
    "\n",
    "从头开始实现Deepseekv2，主要深入理解MOE的推理策略及MLA的实现方法。支持huggingface格式以safetensors为后缀的权重。\n",
    "\n",
    "\n",
    "这里以Deepseek-v2-lite为例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world!'"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import Tokenizer as TokenizerFast\n",
    "import os\n",
    "\n",
    "model_path = \"../deepseek-ai/DeepSeek-V2-Lite/\"\n",
    "\n",
    "tokenizer = TokenizerFast.from_file(os.path.join(model_path, 'tokenizer.json'))\n",
    "tokenizer.decode(tokenizer.encode(\"hello world!\").ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading the model file\n",
    "normally, reading this depends on how the model classes are written and the variable names inside them.\n",
    "<br>\n",
    "but since we are implementing deepseek-v2-lite from scratch we will read the file one tensor at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_head.weight torch.Size([102400, 2048])\n",
      "model.embed_tokens.weight torch.Size([102400, 2048])\n",
      "model.layers.0.input_layernorm.weight torch.Size([2048])\n",
      "model.layers.0.mlp.down_proj.weight torch.Size([2048, 10944])\n",
      "model.layers.0.mlp.gate_proj.weight torch.Size([10944, 2048])\n",
      "model.layers.0.mlp.up_proj.weight torch.Size([10944, 2048])\n",
      "model.layers.0.post_attention_layernorm.weight torch.Size([2048])\n",
      "model.layers.0.self_attn.kv_a_layernorm.weight torch.Size([512])\n",
      "model.layers.0.self_attn.kv_a_proj_with_mqa.weight torch.Size([576, 2048])\n",
      "model.layers.0.self_attn.kv_b_proj.weight torch.Size([4096, 512])\n",
      "model.layers.0.self_attn.o_proj.weight torch.Size([2048, 2048])\n",
      "model.layers.0.self_attn.q_proj.weight torch.Size([3072, 2048])\n",
      "model.layers.1.input_layernorm.weight torch.Size([2048])\n",
      "model.layers.1.mlp.experts.0.down_proj.weight torch.Size([2048, 1408])\n",
      "model.layers.1.mlp.experts.0.gate_proj.weight torch.Size([1408, 2048])\n",
      "model.layers.1.mlp.experts.0.up_proj.weight torch.Size([1408, 2048])\n",
      "model.layers.1.mlp.experts.1.down_proj.weight torch.Size([2048, 1408])\n",
      "model.layers.1.mlp.experts.1.gate_proj.weight torch.Size([1408, 2048])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from safetensors import safe_open\n",
    "model = {}\n",
    "for i in range(1,5):  # 遍历加载权重文件，不同大小的模型需要针对性修改\n",
    "    with safe_open(os.path.join(model_path, f\"model-0000{i}-of-000004.safetensors\"), framework=\"pt\", device=\"cpu\") as f:\n",
    "        count = 1\n",
    "        for k in f.keys():\n",
    "            model[k] = f.get_tensor(k)\n",
    "            count += 1\n",
    "            if count < 20 and i == 1:   # 仅显示部分权重及其shape，作为示例\n",
    "                print(k, model[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aux_loss_alpha': 0.001,\n",
       " 'bos_token_id': 100000,\n",
       " 'eos_token_id': 100001,\n",
       " 'first_k_dense_replace': 1,\n",
       " 'hidden_act': 'silu',\n",
       " 'hidden_size': 2048,\n",
       " 'initializer_range': 0.02,\n",
       " 'intermediate_size': 10944,\n",
       " 'kv_lora_rank': 512,\n",
       " 'max_position_embeddings': 163840,\n",
       " 'model_type': 'deepseek_v2',\n",
       " 'moe_intermediate_size': 1408,\n",
       " 'moe_layer_freq': 1,\n",
       " 'n_group': 1,\n",
       " 'n_routed_experts': 64,\n",
       " 'n_shared_experts': 2,\n",
       " 'norm_topk_prob': False,\n",
       " 'num_attention_heads': 16,\n",
       " 'num_experts_per_tok': 6,\n",
       " 'num_hidden_layers': 27,\n",
       " 'num_key_value_heads': 16,\n",
       " 'pretraining_tp': 1,\n",
       " 'q_lora_rank': None,\n",
       " 'qk_nope_head_dim': 128,\n",
       " 'qk_rope_head_dim': 64,\n",
       " 'rms_norm_eps': 1e-06,\n",
       " 'rope_scaling': {'beta_fast': 32,\n",
       "  'beta_slow': 1,\n",
       "  'factor': 40,\n",
       "  'mscale': 0.707,\n",
       "  'mscale_all_dim': 0.707,\n",
       "  'original_max_position_embeddings': 4096,\n",
       "  'type': 'yarn'},\n",
       " 'rope_theta': 10000,\n",
       " 'routed_scaling_factor': 1.0,\n",
       " 'scoring_func': 'softmax',\n",
       " 'seq_aux': True,\n",
       " 'tie_word_embeddings': False,\n",
       " 'topk_group': 1,\n",
       " 'topk_method': 'greedy',\n",
       " 'torch_dtype': 'bfloat16',\n",
       " 'transformers_version': '4.33.1',\n",
       " 'use_cache': True,\n",
       " 'v_head_dim': 128,\n",
       " 'vocab_size': 102400}"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(os.path.join(model_path, 'config.json'), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "dict(zip(list(config.keys())[4:], list(config.values())[4:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we use this config to infer details about the model like\n",
    "1. the model has 27 transformer layers\n",
    "2. each multi-head attention block has 16 heads\n",
    "3. the vocab size and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = config[\"hidden_size\"]\n",
    "kv_lora_rank = config['kv_lora_rank']                # kv压缩后的维度\n",
    "n_routed_experts = config['n_routed_experts']        # 专家数量\n",
    "n_shared_experts = config['n_shared_experts']        # 共享专家数量\n",
    "n_layers = config[\"num_hidden_layers\"]               # 层数\n",
    "n_heads = config[\"num_attention_heads\"]              # 注意力头数\n",
    "n_experts_per_tok = config['num_experts_per_tok']    # 每个token区topk个专家\n",
    "n_kv_heads = config[\"num_key_value_heads\"]           # kv head数量\n",
    "n_qk_nope_head_dim = config['qk_nope_head_dim']      # 不添加位置编码的维度\n",
    "n_qk_rope_head_dim = config['qk_rope_head_dim']      # 添加位置编码的维度\n",
    "n_v_channels = config[\"v_head_dim\"]                  # value的维度\n",
    "vocab_size = config[\"vocab_size\"]                    # 词表大小\n",
    "norm_eps = config[\"rms_norm_eps\"]\n",
    "rope_theta = 10000.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting text to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1847, 304, 463, 2826, 3572, 11, 359, 317, 457, 8898, 331, 254, 17459, 280]\n",
      "['If', ' I', ' have', ' seen', ' further', ',', ' it', ' is', ' by', ' standing', ' on', ' the', ' shoulders', ' of']\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"the answer to the ultimate question of life, the universe, and everything is \"\n",
    "# prompt = \"Genius is one percent inspiration and\"   #  “ninety-nine percent perspiration.”\n",
    "prompt = \"If I have seen further, it is by standing on the shoulders of\"   #  \" giants.\"\n",
    "tokens = tokenizer.encode(prompt).ids\n",
    "print(tokens)\n",
    "tokens = torch.tensor(tokens)\n",
    "prompt_split_as_tokens = [tokenizer.decode([token.item()]) for token in tokens]\n",
    "print(prompt_split_as_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting tokens to their embedding\n",
    "this is the only part of the codebase where i use an inbuilt neural network module\n",
    "<br>\n",
    "anyway, so our [14x1] tokens are now [2048], i.e. 14 embeddings (one for each token) of length 2048\n",
    "<br>\n",
    "<br>\n",
    "note: keep track of the shapes, it makes it much easier to understand everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = torch.nn.Embedding(vocab_size, dim)\n",
    "embedding_layer.weight.data.copy_(model[\"model.embed_tokens.weight\"])\n",
    "token_embeddings_unnormalized = embedding_layer(tokens).to(torch.bfloat16)\n",
    "token_embeddings_unnormalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we then normalize the embedding using rms normalization\n",
    "please, note after this step the shapes dont change, the values are just normalized\n",
    "<br>\n",
    "things to keep in mind, we need a norm_eps (from config) because we dont want to accidently set rms to 0 and divide by 0\n",
    "<br>\n",
    "here is the formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rms_norm(tensor, norm_weights):\n",
    "#     rms = (tensor.pow(2).mean(-1, keepdim=True) + norm_eps)**0.5\n",
    "#     return tensor * (norm_weights / rms)\n",
    "def rms_norm(tensor, norm_weights):\n",
    "    input_type = tensor.dtype\n",
    "    tensor = tensor.to(torch.float32)\n",
    "    tensor = tensor * torch.rsqrt(tensor.pow(2).mean(-1, keepdim=True) + norm_eps)\n",
    "    return tensor.to(input_type) * norm_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building the first layer of the transformer\n",
    "\n",
    "### normalization\n",
    "you will see me accessing layer.0 from the model dict (this is the first layer)\n",
    "<br>\n",
    "anyway, so after normalizing our shapes are still [14x2048] same as embedding but normalized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = rms_norm(token_embeddings_unnormalized, model[\"model.layers.0.input_layernorm.weight\"])\n",
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attention implemented from scratch\n",
    "let's load the attention heads of the first layer of the transformer\n",
    "\n",
    "&gt; 从模型中加载q、k、v和输出投影层的权重\n",
    "<br>\n",
    "&gt; q_proj是q的权重，kv_a是kv的压缩权重，kv_b是kv投影回原始维度的映射权重\n",
    "<br>\n",
    "&gt; 具体可以参考Deepseek V2的论文，MLA是一个重要的创新点，主要目的是节省kvcache的大小。类似于LoRA，先通过kv_a将输入维度压缩，然后再解压缩回原始维度。在kvcache时只需要保存压缩后的部分即可；\n",
    "<br>\n",
    "&gt; 对于lite模型，就是先通过kv_a将维度从2048压缩至576，然后拆分为512(kv_lora_rank)和64(n_qk_rope_head_dim)，512的部分不添加旋转位置编码，通过kv_b映射回2048，而64则添加位置编码。\n",
    "<br>\n",
    "&gt; 这里kv_b是4096，是因为包含了k和v，所以是2048*2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 2048]) torch.Size([576, 2048]) torch.Size([512]) torch.Size([4096, 512]) torch.Size([2048, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    model[\"model.layers.0.self_attn.q_proj.weight\"].shape,\n",
    "    model[\"model.layers.0.self_attn.kv_a_proj_with_mqa.weight\"].shape,\n",
    "    model[\"model.layers.0.self_attn.kv_a_layernorm.weight\"].shape,\n",
    "    model[\"model.layers.0.self_attn.kv_b_proj.weight\"].shape,\n",
    "    model[\"model.layers.0.self_attn.o_proj.weight\"].shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unwrapping query\n",
    "in the next section we will unwrap the queries from multiple attention heads, the resulting shape is [16x192x2048]\n",
    "<br><br>\n",
    "here, 16 is the number of attention heads in deepseek-v2-lite, 192 is the size of the query vector and 2048 is the size of the token embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 192, 2048])\n"
     ]
    }
   ],
   "source": [
    "q_layer0 = model[\"model.layers.0.self_attn.q_proj.weight\"]\n",
    "q_layer0 = q_layer0.reshape(n_heads, n_qk_nope_head_dim+n_qk_rope_head_dim, -1)\n",
    "print(q_layer0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### im going to implement the first head of the first layer\n",
    "here i access the query weight matrix first head of the first layer, the size of this query weight matrix is [192x2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 2048])"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_layer0_head0 = q_layer0[0]\n",
    "q_layer0_head0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里将q的维度192拆分为128和64，其中128对应不参与位置编码部分，64对应参与位置编码部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 2048]), torch.Size([64, 2048]))"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_layer0_head0_nope, q_layer0_head0_pe = torch.split(q_layer0_head0, [n_qk_nope_head_dim, n_qk_rope_head_dim], dim=0)\n",
    "q_layer0_head0_nope.shape, q_layer0_head0_pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we now multiply the query weights with the token embedding, to recive a query for the token\n",
    "here you can see the resulting shape is [14x128], this is because we have 14 tokens and for each token there is a 128 or 64 length query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 128]), torch.Size([14, 64]))"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_per_token_nope = torch.matmul(token_embeddings, q_layer0_head0_nope.T)\n",
    "q_per_token_pe = torch.matmul(token_embeddings, q_layer0_head0_pe.T)\n",
    "q_per_token_nope.shape, q_per_token_pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keys and values\n",
    "k和v的权重是在一起的，映射完再拆分为k和v。\n",
    "<br><br>\n",
    "这里先将不参与位置编码和参与位置编码的映射权重拆分开，分别进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 2048]), torch.Size([64, 2048]))"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_layer0 = model[\"model.layers.0.self_attn.kv_a_proj_with_mqa.weight\"]\n",
    "kv_layer0_compressed, kv_layer0_rope =  torch.split(kv_layer0, [kv_lora_rank, n_qk_rope_head_dim], dim=0)\n",
    "kv_layer0_compressed.shape, kv_layer0_rope.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一部分不参与位置编码，是MLA中的压缩部分。将2048压缩到512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 512])"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_per_token_compressed = torch.matmul(token_embeddings, kv_layer0_compressed.T)\n",
    "kv_per_token_compressed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后再映射回2048，这里是4096，因为里面包含着k和v，下面会拆开。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 4096])"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_layer0_norm = model[\"model.layers.0.self_attn.kv_a_layernorm.weight\"]\n",
    "kv_layer0_b = model[\"model.layers.0.self_attn.kv_b_proj.weight\"]\n",
    "kv_per_token_b = torch.matmul(rms_norm(kv_per_token_compressed, kv_layer0_norm), kv_layer0_b.T)\n",
    "kv_per_token_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照heads数量调整维度，16是num_heads，14是tokens长度，256是k和v的维度，128*2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 14, 256])"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_per_token_compressed = kv_per_token_b.reshape(len(tokens), n_heads, n_qk_nope_head_dim+n_v_channels).transpose(0,1)\n",
    "kv_per_token_compressed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "沿着最后一维(256)拆开，变成两个128，分别是k和v的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 14, 128]), torch.Size([16, 14, 128]))"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_per_token_nope, v_states = torch.split(kv_per_token_compressed, [n_qk_nope_head_dim, n_v_channels], dim=-1)\n",
    "k_per_token_nope.shape, v_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一部分是参与计算旋转位置编码的部分。注意，上面不参与位置编码的部分是变换成16个head了，但是这里参与位置编码的部分，并没有进行变换，所以这一部分是所有head共享的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 64])"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_per_token_rope = torch.matmul(token_embeddings, kv_layer0_rope.T)\n",
    "kv_per_token_rope.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## positioning encoding\n",
    "we are now at a stage where we have a query vector for each token in our prompt, but if you think about it -- the indivitually query vector has no idea about the position in the prompt.\n",
    "<br>\n",
    "### RoPE\n",
    "Deepseek V2的位置编码比原版RoPE相对要复杂一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Inverse dim formula to find dim based on number of rotations\n",
    "def yarn_find_correction_dim(num_rotations, dim, base=10000, max_position_embeddings=2048):\n",
    "    return (dim * math.log(max_position_embeddings / (num_rotations * 2 * math.pi))) / (2 * math.log(base))\n",
    "\n",
    "# Find dim range bounds based on rotations\n",
    "def yarn_find_correction_range(low_rot, high_rot, dim, base=10000, max_position_embeddings=2048):\n",
    "    low = math.floor(yarn_find_correction_dim(low_rot, dim, base, max_position_embeddings))\n",
    "    high = math.ceil(yarn_find_correction_dim(high_rot, dim, base, max_position_embeddings))\n",
    "    return max(low, 0), min(high, dim - 1)  # Clamp values just in case\n",
    "\n",
    "def yarn_get_mscale(scale=1, mscale=1):\n",
    "    if scale <= 1:\n",
    "        return 1.0\n",
    "    return 0.1 * mscale * math.log(scale) + 1.0\n",
    "\n",
    "def yarn_linear_ramp_mask(min, max, dim):\n",
    "    if min == max:\n",
    "        max += 0.001  # Prevent singularity\n",
    "    linear_func = (torch.arange(dim, dtype=torch.float32) - min) / (max - min)\n",
    "    ramp_func = torch.clamp(linear_func, 0, 1)\n",
    "    return ramp_func\n",
    "\n",
    "# Copied from transformers.models.llama.modeling_llama.rotate_half\n",
    "def rotate_half(x):\n",
    "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预设了最大长度为100，先提前计算出cos_cached和sin_cached，后续可以根据序列长度取出对应的值，直接应用于q和k。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "dim = n_qk_rope_head_dim\n",
    "freq_extra = 1.0 / (rope_theta ** (torch.arange(0, dim, 2, dtype=torch.float32, device='cpu') / dim))\n",
    "freq_inter = 1.0 / (config['rope_scaling']['factor']  * rope_theta ** (torch.arange(0, dim, 2, dtype=torch.float32, device='cpu') / dim))\n",
    "\n",
    "low, high = yarn_find_correction_range(config['rope_scaling']['beta_fast'], config['rope_scaling']['beta_slow'], dim, rope_theta,  config['rope_scaling']['original_max_position_embeddings'])\n",
    "inv_freq_mask = 1.0 - yarn_linear_ramp_mask(low, high, dim // 2).to(device='cpu', dtype=torch.float32)\n",
    "inv_freq = freq_inter * (1 - inv_freq_mask) + freq_extra * inv_freq_mask\n",
    "\n",
    "t = torch.arange(max_len, device='cpu', dtype=torch.float32)\n",
    "\n",
    "freqs = torch.outer(t, inv_freq)\n",
    "\n",
    "_mscale = float(\n",
    "            yarn_get_mscale(config['rope_scaling']['factor'], config['rope_scaling']['mscale'])\n",
    "            / yarn_get_mscale(config['rope_scaling']['factor'], config['rope_scaling']['mscale_all_dim']))\n",
    "\n",
    "emb = torch.cat((freqs, freqs), dim=-1)\n",
    "\n",
    "cos_cached = (emb.cos() * _mscale).to(torch.bfloat16)\n",
    "sin_cached = (emb.sin() * _mscale).to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为q和k添加位置编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 64]), torch.Size([14, 64]))"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_seq_len = v_states.shape[-2]\n",
    "cos, sin = cos_cached[:kv_seq_len], sin_cached[:kv_seq_len]   # 取出对应长度的部分\n",
    "cos.shape, sin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 64]), torch.Size([14, 64]))"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, d = q_per_token_pe.shape\n",
    "q_per_token_pe = q_per_token_pe.view(s, d // 2, 2).transpose(2, 1).reshape(s, d)\n",
    "\n",
    "s, d = kv_per_token_rope.shape\n",
    "kv_per_token_rope = kv_per_token_rope.view(s, d // 2, 2).transpose(2, 1).reshape(s, d)\n",
    "\n",
    "q_per_token_pe = (q_per_token_pe * cos) + (rotate_half(q_per_token_pe) * sin)\n",
    "k_per_token_pe = (kv_per_token_rope * cos) + (rotate_half(kv_per_token_rope) * sin)\n",
    "\n",
    "q_per_token_pe.shape, k_per_token_pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于q和k分别包含了添加位置编码和不添加位置编码的两个部分，因此在计算完位置编码后需要将两部分拼接到一起，从而得到完整的q和k。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 192])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_states = k_per_token_pe.new_empty(q_per_token_pe.shape[0], n_qk_nope_head_dim+n_qk_rope_head_dim)\n",
    "query_states[:, : n_qk_nope_head_dim] = q_per_token_nope\n",
    "query_states[:, n_qk_nope_head_dim :] = q_per_token_pe\n",
    "query_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 192])"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_states = k_per_token_pe.new_empty(k_per_token_pe.shape[0], n_qk_nope_head_dim+n_qk_rope_head_dim)\n",
    "key_states[:, : n_qk_nope_head_dim] = k_per_token_nope[0]   # head 0\n",
    "key_states[:, n_qk_nope_head_dim :] = k_per_token_pe\n",
    "key_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## at this stage now have both the rotated values of queries and keys, for each token. \n",
    "each of the queries and keys are now of shape [14x192]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in the next step we will multiply the queries and key matrices\n",
    "doing this will give us a score mapping each token with one another\n",
    "<br>\n",
    "this score describes how well each token's query relates to the each tokens's key. \n",
    "THIS IS SELF ATTENTION :)\n",
    "<br>\n",
    "the shape of the attention score matrix (qk_per_token) is [14x14] where 14 is the number of tokens in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 14])"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mscale = 0.1 * config['rope_scaling'][\"mscale_all_dim\"] * math.log(config['rope_scaling'][\"factor\"]) + 1.0\n",
    "softmax_scale = (n_qk_nope_head_dim+n_qk_rope_head_dim) ** (0.5) * mscale * mscale         # Deepseek v2 注意力中除以d，是通过系数和维度一通操作算出的，不是简单的hidden_dim的平方根\n",
    "qk_per_token = torch.matmul(query_states, key_states.T)/softmax_scale\n",
    "qk_per_token.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we now have to mask query key scores\n",
    "during the training process of deepseek-v2-lite, the future token qk scores are masked.\n",
    "<br>\n",
    "why? because during training we only learn to predict tokens using past tokens.\n",
    "<br>\n",
    "as a result, during inference we set the future tokens to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def display_qk_heatmap(qk_per_token):\n",
    "    _, ax = plt.subplots()\n",
    "    im = ax.imshow(qk_per_token.to(float).detach(), cmap='viridis')\n",
    "    ax.set_xticks(range(len(prompt_split_as_tokens)))\n",
    "    ax.set_yticks(range(len(prompt_split_as_tokens)))\n",
    "    ax.set_xticklabels(prompt_split_as_tokens)\n",
    "    ax.set_yticklabels(prompt_split_as_tokens)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "display_qk_heatmap(qk_per_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full((len(tokens), len(tokens)), float(\"-inf\"), device=tokens.device)\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qk_per_token_after_masking = qk_per_token + mask\n",
    "display_qk_heatmap(qk_per_token_after_masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qk_per_token_after_masking_after_softmax = torch.nn.functional.softmax(qk_per_token_after_masking, dim=1, dtype=torch.float32).to(torch.bfloat16)\n",
    "display_qk_heatmap(qk_per_token_after_masking_after_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value vectors\n",
    "we now use the value weghts to get the attention values per token, this is of size [14x128] where 14 is the number of tokens in the prompt and 128 is the dim of the value vector per token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 128])"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_per_token = v_states[0]\n",
    "v_per_token.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attention\n",
    "the resultant attention vector after multipying with the values per token is of shape [14*128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 128])"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)\n",
    "qkv_attention.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi head attention\n",
    "We now have the attention value of the first layer and first head\n",
    "<br>\n",
    "now im going to run a loop and perform the exact same math as the cells above but for every head in the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_attention_store = []\n",
    "for head in range(n_heads):    # 循环head，逐个计算\n",
    "    q_layer0_head = q_layer0[head]\n",
    "    q_layer0_head_nope, q_layer0_head_pe = torch.split(q_layer0_head, [n_qk_nope_head_dim, n_qk_rope_head_dim], dim=0)\n",
    "    q_per_token_nope = torch.matmul(token_embeddings, q_layer0_head_nope.T)\n",
    "    q_per_token_pe = torch.matmul(token_embeddings, q_layer0_head_pe.T)\n",
    "    \n",
    "    k_layer0_head_nope = k_per_token_nope[head]   # 不计算位置编码的部分区分head\n",
    "    v_per_token = v_states[head]\n",
    "    \n",
    "    kv_seq_len = v_per_token.shape[0]\n",
    "    cos, sin = cos_cached[:kv_seq_len], sin_cached[:kv_seq_len]\n",
    "    \n",
    "    # k的位置编码前面已经计算过了，且同一层head共享一份，所以heads的循环里面只需要为q添加位置编码就行了。\n",
    "    s, d = q_per_token_pe.shape\n",
    "    q_per_token_pe = q_per_token_pe.view(s, d // 2, 2).transpose(2, 1).reshape(s, d)  \n",
    "    q_per_token_pe = (q_per_token_pe * cos) + (rotate_half(q_per_token_pe) * sin)\n",
    "    # 拼接q\n",
    "    query_states = k_per_token_pe.new_empty(q_per_token_pe.shape[0], n_qk_nope_head_dim+n_qk_rope_head_dim)\n",
    "    query_states[:, : n_qk_nope_head_dim] = q_per_token_nope\n",
    "    query_states[:, n_qk_nope_head_dim :] = q_per_token_pe\n",
    "    # 拼接k\n",
    "    key_states = k_per_token_pe.new_empty(k_per_token_pe.shape[0], n_qk_nope_head_dim+n_qk_rope_head_dim)\n",
    "    key_states[:, : n_qk_nope_head_dim] = k_layer0_head_nope\n",
    "    key_states[:, n_qk_nope_head_dim :] = k_per_token_pe     # 计算位置编码的部分，同一层的所有head共享一份\n",
    "    # 计算注意力\n",
    "    qk_per_token = torch.matmul(query_states, key_states.T)/softmax_scale\n",
    "    # 添加掩码\n",
    "    mask = torch.full((len(tokens), len(tokens)), float(\"-inf\"), device=tokens.device)\n",
    "    mask = torch.triu(mask, diagonal=1)\n",
    "    qk_per_token_after_masking = qk_per_token + mask\n",
    "    \n",
    "    qk_per_token_after_masking_after_softmax = torch.nn.functional.softmax(qk_per_token_after_masking, dim=1, dtype=torch.float32).to(torch.bfloat16)\n",
    "\n",
    "    qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)\n",
    "    \n",
    "    qkv_attention_store.append(qkv_attention)\n",
    "\n",
    "print(qkv_attention_store[0].shape)\n",
    "len(qkv_attention_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now have a the qkv_attention matrix for all 16 heads on the first layer, next im going to merge all attention scores into one large matrix of size [14x2048]\n",
    "<br>\n",
    "we are almost at the end :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_qkv_attention = torch.cat(qkv_attention_store, dim=-1)\n",
    "stacked_qkv_attention.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight matrix, one of the final steps\n",
    "one of the last things to do for a layer 0 attention is, is to multiply the weight matrix of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 2048])"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_layer0 = model[\"model.layers.0.self_attn.o_proj.weight\"]\n",
    "w_layer0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is a simple linear layer, so we just matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_delta = torch.matmul(stacked_qkv_attention, w_layer0.T)\n",
    "embedding_delta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now have the change in the embedding value after attention, that should be adding to the original token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_after_edit = token_embeddings_unnormalized + embedding_delta\n",
    "embedding_after_edit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we normalize and then run a feed forward neural network through the embedding delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_after_edit_normalized = rms_norm(embedding_after_edit, model[\"model.layers.0.post_attention_layernorm.weight\"])\n",
    "embedding_after_edit_normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the ff weights and implementing the feed forward network\n",
    "in deepseek-v2-lite, they used a SwiGLU feedforward network, this network architecture is really good at adding non linearity when needed by the model.\n",
    "<br>\n",
    "its pretty standard to use this feed forward network architecture in llms these days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = model[\"model.layers.0.mlp.gate_proj.weight\"]\n",
    "w2 = model[\"model.layers.0.mlp.down_proj.weight\"]\n",
    "w3 = model[\"model.layers.0.mlp.up_proj.weight\"]\n",
    "\n",
    "output_after_feedforward = torch.matmul(torch.functional.F.silu(torch.matmul(embedding_after_edit_normalized, w1.T)) * torch.matmul(embedding_after_edit_normalized, w3.T), w2.T)\n",
    "output_after_feedforward.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We finally have new edited embeddings for each token after the first layer \n",
    "\n",
    "you can imagine this edited embedding as having information about all queries asked on the first layer\n",
    "<br>\n",
    "now each layer will encode more and more complex queries on the quesions asked, until we have an embedding that knows everything about the next token that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0_embedding = embedding_after_edit+output_after_feedforward\n",
    "layer_0_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUT\n",
    "MOE结构好像还没出现。\n",
    "<br>\n",
    "\n",
    "其实是因为Deepseek-V2-Lite第一层并没有使用MOE，而是从第二层开始才使用MOE层替换FFN，所以继续看第二层的分解流程。\n",
    "<br>\n",
    "\n",
    "前面的self-attn部分和第一层是一样的，直接全部执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings_unnormalized = layer_0_embedding\n",
    "token_embeddings = rms_norm(token_embeddings_unnormalized, model[\"model.layers.1.input_layernorm.weight\"])\n",
    "q_layer1 = model[\"model.layers.1.self_attn.q_proj.weight\"]\n",
    "q_layer1 = q_layer1.reshape(n_heads, n_qk_nope_head_dim+n_qk_rope_head_dim, -1)\n",
    "\n",
    "kv_layer1 = model[\"model.layers.1.self_attn.kv_a_proj_with_mqa.weight\"]\n",
    "kv_layer1_compressed, kv_layer1_rope =  torch.split(kv_layer1, [kv_lora_rank, n_qk_rope_head_dim], dim=0)\n",
    "kv_per_token_compressed = torch.matmul(token_embeddings, kv_layer1_compressed.T)\n",
    "kv_per_token_rope = torch.matmul(token_embeddings, kv_layer1_rope.T)\n",
    "kv_layer1_norm = model[\"model.layers.1.self_attn.kv_a_layernorm.weight\"]\n",
    "kv_layer1_b = model[\"model.layers.1.self_attn.kv_b_proj.weight\"]\n",
    "kv_per_token_b = torch.matmul(rms_norm(kv_per_token_compressed, kv_layer1_norm), kv_layer1_b.T)\n",
    "kv_per_token_compressed = kv_per_token_b.reshape(len(tokens), n_heads, n_qk_nope_head_dim+n_v_channels).transpose(0,1)\n",
    "k_per_token_nope, v_states = torch.split(kv_per_token_compressed, [n_qk_nope_head_dim, n_v_channels], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_attention_store = []\n",
    "for head in range(n_heads):\n",
    "    q_layer1_head = q_layer1[head]\n",
    "    q_layer1_head_nope, q_layer1_head_pe = torch.split(q_layer1_head, [n_qk_nope_head_dim, n_qk_rope_head_dim], dim=0)\n",
    "    q_per_token_nope = torch.matmul(token_embeddings, q_layer1_head_nope.T)\n",
    "    q_per_token_pe = torch.matmul(token_embeddings, q_layer1_head_pe.T)\n",
    "    \n",
    "    k_layer1_head_nope = k_per_token_nope[head]\n",
    "    v_per_token = v_states[head]\n",
    "    \n",
    "    kv_seq_len = v_per_token.shape[0]\n",
    "    cos, sin = cos_cached[:kv_seq_len], sin_cached[:kv_seq_len]\n",
    "    \n",
    "    s, d = q_per_token_pe.shape\n",
    "    q_per_token_pe = q_per_token_pe.view(s, d // 2, 2).transpose(2, 1).reshape(s, d)   \n",
    "    q_per_token_pe = (q_per_token_pe * cos) + (rotate_half(q_per_token_pe) * sin)\n",
    "    \n",
    "    query_states = k_per_token_pe.new_empty(q_per_token_pe.shape[0], n_qk_nope_head_dim+n_qk_rope_head_dim)\n",
    "    query_states[:, : n_qk_nope_head_dim] = q_per_token_nope\n",
    "    query_states[:, n_qk_nope_head_dim :] = q_per_token_pe\n",
    "    \n",
    "    key_states = k_per_token_pe.new_empty(k_per_token_pe.shape[0], n_qk_nope_head_dim+n_qk_rope_head_dim)\n",
    "    key_states[:, : n_qk_nope_head_dim] = k_layer1_head_nope   # head 0\n",
    "    key_states[:, n_qk_nope_head_dim :] = k_per_token_pe\n",
    "    \n",
    "    qk_per_token = torch.matmul(query_states, key_states.T)/softmax_scale\n",
    "    \n",
    "    mask = torch.full((len(tokens), len(tokens)), float(\"-inf\"), device=tokens.device)\n",
    "    mask = torch.triu(mask, diagonal=1)\n",
    "    qk_per_token_after_masking = qk_per_token + mask\n",
    "    \n",
    "    qk_per_token_after_masking_after_softmax = torch.nn.functional.softmax(qk_per_token_after_masking, dim=1, dtype=torch.float32).to(torch.bfloat16)\n",
    "\n",
    "    qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)\n",
    "    \n",
    "    qkv_attention_store.append(qkv_attention)\n",
    "\n",
    "print(qkv_attention_store[0].shape)\n",
    "len(qkv_attention_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_qkv_attention = torch.cat(qkv_attention_store, dim=-1)\n",
    "w_layer1 = model[\"model.layers.1.self_attn.o_proj.weight\"]\n",
    "embedding_delta = torch.matmul(stacked_qkv_attention, w_layer1.T)\n",
    "embedding_after_edit = token_embeddings_unnormalized + embedding_delta\n",
    "embedding_after_edit_normalized = rms_norm(embedding_after_edit, model[\"model.layers.1.post_attention_layernorm.weight\"])\n",
    "embedding_after_edit_normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOE 从这里开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2048])\n",
      "torch.Size([2816, 2048])\n",
      "torch.Size([2816, 2048])\n",
      "torch.Size([2048, 2816])\n",
      "torch.Size([1408, 2048])\n",
      "torch.Size([1408, 2048])\n",
      "torch.Size([2048, 1408])\n"
     ]
    }
   ],
   "source": [
    "# 打印部分权重的shape\n",
    "print(model['model.layers.1.mlp.gate.weight'].shape)\n",
    "print(model['model.layers.1.mlp.shared_experts.gate_proj.weight'].shape)\n",
    "print(model['model.layers.1.mlp.shared_experts.up_proj.weight'].shape)\n",
    "print(model['model.layers.1.mlp.shared_experts.down_proj.weight'].shape)\n",
    "print(model['model.layers.1.mlp.experts.0.gate_proj.weight'].shape)\n",
    "print(model['model.layers.1.mlp.experts.0.up_proj.weight'].shape)\n",
    "print(model['model.layers.1.mlp.experts.0.down_proj.weight'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shard exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = model[\"model.layers.1.mlp.shared_experts.gate_proj.weight\"]\n",
    "w2 = model[\"model.layers.1.mlp.shared_experts.down_proj.weight\"]\n",
    "w3 = model[\"model.layers.1.mlp.shared_experts.up_proj.weight\"]\n",
    "\n",
    "output_after_shardexports = torch.matmul(torch.functional.F.silu(torch.matmul(embedding_after_edit_normalized, w1.T)) * torch.matmul(embedding_after_edit_normalized, w3.T), w2.T)\n",
    "output_after_shardexports.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### route exports\n",
    "Gate\n",
    "<br>\n",
    "决定每个token应该发送到哪几个专家。topk=6，也就是每个token选6个专家。\n",
    "<br><br>\n",
    "这里得到14x64，14是token数量，64是对应64个专家。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 64])"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_logits = torch.matmul(embedding_after_edit_normalized, model['model.layers.1.mlp.gate.weight'].T)\n",
    "gate_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对每个token在64个专家上计算softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 64])"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_scores = gate_logits.softmax(dim=-1, dtype=torch.float32)\n",
    "gate_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个token取topk个专家的值和对应的id。\n",
    "<br>\n",
    "weight表示softmax之后最大的前6个值，idx表示这6个值对应的id，也即是专家的序号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 6]), torch.Size([14, 6]))"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_weight, topk_idx = torch.topk(gate_scores, k=n_experts_per_tok, dim=-1, sorted=False)\n",
    "topk_weight.shape, topk_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个14x64的全0矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 64])"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnts = topk_idx.new_zeros((topk_idx.shape[0], n_routed_experts))\n",
    "cnts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个token对应一行。将每个token要发送到的专家所在的位置置1.\n",
    "<br>\n",
    "假设第一个token被分配到序号为第 0，2，10，38，40，63 共计6个专家，则cnts第一行的第 0，2，10，38，40，63位置为1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnts.scatter_(1, topk_idx, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对dim=0求和，得到每个专家分配到的token数。\n",
    "<br>\n",
    "注意区别，虽然每个token会被发送到6个专家的，但是每个专家接收的token数量并不一定，也许会接收多个，也许是一个，也许一个也不接收。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 0, 1, 1, 2, 3, 0, 3, 1, 0, 4, 1, 0, 1, 0, 0, 5, 2, 1, 2, 1, 1, 2,\n",
       "        4, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 0, 3, 3, 0, 0, 2, 3, 3, 2, 0, 2, 0,\n",
       "        1, 0, 0, 1, 3, 0, 1, 2, 0, 0, 3, 0, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_expert = cnts.sum(dim=0)\n",
    "tokens_per_expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topk_idx中存的是每个token被分配的专家的序号。\n",
    "<br>\n",
    "对topk_idx进行排序，则是将所有token选择的所有专家的序号进行排序，argsort()返回的是排序后的值在排序前所在的序号。\n",
    "<br>\n",
    "排序前，topk_idx里面共计14*6=84个数值，每个值都是一个token选择的一个专家序号，这个序号是64个专家的序号。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idxs是按照专家序号排序后的原位置的索引，也就是按照64个专家的序号排序，返回的是排序前的位置。比如第3个token选择的第5个专家是38，那么topk_idx在view后的第(3-1)*6+(5-1)=16个位置的值是38。-1是因为序号是从0开始。\n",
    "<br><br>\n",
    "将专家序号按照从小到大的排序后，假设38号专家排在第45位，那么idxs的第45个位置的值，就是16. 也就是idxs里面存的是排序后该位置的值在排序前所在的位置。\n",
    "<br><br>\n",
    "注意，前面说过每个token选择6个专家是提前设定的，但是每个专家是否被选择、同时被几个token选择，是不固定的，所以38号专家按照序号排序时排在哪个位置，都是有可能的。当然由于每个专家最大接收数量一般也有限制，所以38号排序时基本不会出现在前几个或者最后几个，这是特例不用纠结。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46, 27, 48, 82, 64, 77, 34, 12, 45, 39, 10, 66, 16,  6, 68, 25, 35,  8,\n",
       "        70, 29, 71, 24, 69, 51, 65, 17, 54, 57, 72, 73, 44, 36, 67,  4, 19, 14,\n",
       "        63,  3, 50, 81, 11, 40, 42, 30, 52, 47, 76, 21, 78, 56, 28, 18, 43, 53,\n",
       "        15, 61, 23, 55, 26,  0, 83,  1, 31, 80, 32,  2,  7, 20, 33, 60, 49, 79,\n",
       "        58, 62, 37, 75, 22, 59, 41, 74,  9, 38, 13,  5])"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = topk_idx.view(-1).argsort()\n",
    "idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里是按照排序后的索引取token。\n",
    "<br><br>\n",
    "书接上文。假设idxs第45个位置的值是16，对应的是38号专家。则 idxs[44] // topk_idx.shape[1] 就是 16//6=2，也就是对应3个token。\n",
    "<br><br>\n",
    "所以 idxs // topk_idx.shape[1] 就是拿专家排序前的索引，找到选择该专家的token索引。然后根据该所以取出来token放到排序后专家所在的位置，这样就可以生成一个按照排序后专家的顺序对应的token，也就是将同一个专家接收的token放到了一起，可以很方便的通过遍历专家一块处理。\n",
    "<br><br>\n",
    "sorted_tokens的维度是84*2048，2048是Embedding维度，84是什么？就是14个token，每个token选择了6个专家，也就是说64个专家被选择了84次。所以现在按照这84次，取出了对应的token。\n",
    "<br><br>\n",
    "这84个token排序是按照所有token选择的所有专家的序号拍的，比如有2个token选择了0号专家，则在这84的前两个就表示选择了0号专家的2个token。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 2048])"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tokens = embedding_after_edit_normalized[idxs // topk_idx.shape[1]]\n",
    "sorted_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokens_per_expert是每个专家被选择的次数，也就是每个专家要处理的token数。\n",
    "<br><br>\n",
    "比如第0号专家，有两个token选择，则tokens_per_expert的第一个元素是2，而sorted_tokens的前两个正好就是选择了0号专家的2个token。因此通过遍历tokens_per_expert即可依次取出每个专家要处理的token，并行处理。\n",
    "<br><br>\n",
    "如果tokens_per_expert的某个元素是0，则表示该专家没有token选取，直接跳过即可。\n",
    "<br><br>\n",
    "处理完成后再拼接回84x2048，shape不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 2048])"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_expert = tokens_per_expert.cpu().numpy()\n",
    "outputs = []\n",
    "start_idx = 0\n",
    "for i, num_tokens in enumerate(tokens_per_expert):\n",
    "    end_idx = start_idx + num_tokens\n",
    "    if num_tokens == 0:\n",
    "        continue\n",
    "    w1 = model[f\"model.layers.1.mlp.experts.{i}.gate_proj.weight\"]\n",
    "    w2 = model[f\"model.layers.1.mlp.experts.{i}.down_proj.weight\"]\n",
    "    w3 = model[f\"model.layers.1.mlp.experts.{i}.up_proj.weight\"]\n",
    "    tokens_for_this_expert = sorted_tokens[start_idx:end_idx]\n",
    "    expert_out = torch.matmul(torch.functional.F.silu(torch.matmul(tokens_for_this_expert, w1.T)) * torch.matmul(tokens_for_this_expert, w3.T), w2.T)\n",
    "    outputs.append(expert_out)\n",
    "    start_idx = end_idx\n",
    "\n",
    "outs = torch.cat(outputs, dim=0) if len(outputs) else sorted_tokens.new_empty(0)\n",
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 2048])"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x = torch.empty_like(outs)\n",
    "new_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里和前面的处理相呼应，是逆变换。\n",
    "<br><br>\n",
    "回想上面的sorted_tokens是怎么产生的。是按照所有token选择的所有专家的序号，取token生成的。所以14个token共计选择84个专家(总共64个专家，有重复选取)，然后按照84个专家的采样了14个token，每个token被采样了6次。\n",
    "<br><br>\n",
    "现在token被所有专家处理完了，要被映射回去。从按照专家序号排序，变回按照token顺序排序。\n",
    "<br><br>\n",
    "和上面一样，假设idxs第45个位置的值是16，那么new_x[16]=outs[45]，和之前的变化正好反过来。变换后，16这个位置的值就是第3个token被第5个专家处理后的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 2048])"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x[idxs] = outs\n",
    "new_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里要对一个token经过6个专家处理后的结果做加权处理。\n",
    "<br><br>\n",
    "new_x.view(*topk_idx.shape, -1)将84x2048变成14x6x2048，然后再和topk_weights相乘。类似于self-attn中attention 乘以 value vector。\n",
    "<br><br> 最后再第1维进行求和，变成14x2048。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_after_routeexports = new_x.view(*topk_idx.shape, -1).type(topk_weight.dtype).mul_(topk_weight.unsqueeze(dim=-1)).sum(dim=1).type(new_x.dtype)\n",
    "output_after_routeexports.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOE部分最终输出\n",
    "<br><br>\n",
    "将共享专家处理的结果和route专家生成的结果求和，作为最终的MOE结果输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out = output_after_shardexports + output_after_routeexports\n",
    "final_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_embedding = embedding_after_edit + final_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## god, everything all at once\n",
    "yep, this is it. everything we did before, all at once, for every single layer.\n",
    "<br>\n",
    "\n",
    "## have fun reading :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_cache, v_cache = [], []   # init k v cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_embedding = layer_0_embedding\n",
    "for layer in range(1, n_layers):\n",
    "    token_embeddings = rms_norm(final_embedding, model[f\"model.layers.{layer}.input_layernorm.weight\"])\n",
    "    q_layer = model[f\"model.layers.{layer}.self_attn.q_proj.weight\"]\n",
    "    q_layer = q_layer.reshape(n_heads, n_qk_nope_head_dim+n_qk_rope_head_dim, -1)\n",
    "\n",
    "    kv_layer = model[f\"model.layers.{layer}.self_attn.kv_a_proj_with_mqa.weight\"]\n",
    "    kv_layer_compressed, kv_layer_rope =  torch.split(kv_layer, [kv_lora_rank, n_qk_rope_head_dim], dim=0)\n",
    "    kv_per_token_compressed = torch.matmul(token_embeddings, kv_layer_compressed.T)\n",
    "    kv_per_token_rope = torch.matmul(token_embeddings, kv_layer_rope.T)\n",
    "    kv_layer_norm = model[f\"model.layers.{layer}.self_attn.kv_a_layernorm.weight\"]\n",
    "    kv_layer_b = model[f\"model.layers.{layer}.self_attn.kv_b_proj.weight\"]\n",
    "    kv_per_token_b = torch.matmul(rms_norm(kv_per_token_compressed, kv_layer_norm), kv_layer_b.T)\n",
    "    kv_per_token_compressed = kv_per_token_b.reshape(len(tokens), n_heads, n_qk_nope_head_dim+n_v_channels).transpose(0,1)\n",
    "    k_per_token_nope, v_states = torch.split(kv_per_token_compressed, [n_qk_nope_head_dim, n_v_channels], dim=-1)\n",
    "\n",
    "    s, d = kv_per_token_rope.shape\n",
    "    kv_per_token_rope = kv_per_token_rope.view(s, d // 2, 2).transpose(2, 1).reshape(s, d)\n",
    "    k_per_token_pe = (kv_per_token_rope * cos) + (rotate_half(kv_per_token_rope) * sin)\n",
    "    \n",
    "    qkv_attention_store = []\n",
    "    for head in range(n_heads):\n",
    "        q_layer_head = q_layer[head]\n",
    "        q_layer_head_nope, q_layer_head_pe = torch.split(q_layer_head, [n_qk_nope_head_dim, n_qk_rope_head_dim], dim=0)\n",
    "        q_per_token_nope = torch.matmul(token_embeddings, q_layer_head_nope.T)\n",
    "        q_per_token_pe = torch.matmul(token_embeddings, q_layer_head_pe.T)\n",
    "        \n",
    "        k_layer_head_nope = k_per_token_nope[head]\n",
    "        v_per_token = v_states[head]\n",
    "        \n",
    "        kv_seq_len = v_per_token.shape[0]\n",
    "        cos, sin = cos_cached[:kv_seq_len], sin_cached[:kv_seq_len]\n",
    "        \n",
    "        s, d = q_per_token_pe.shape\n",
    "        q_per_token_pe = q_per_token_pe.view(s, d // 2, 2).transpose(2, 1).reshape(s, d) \n",
    "        q_per_token_pe = (q_per_token_pe * cos) + (rotate_half(q_per_token_pe) * sin)\n",
    "        \n",
    "        query_states = k_per_token_pe.new_empty(q_per_token_pe.shape[0], n_qk_nope_head_dim+n_qk_rope_head_dim)\n",
    "        query_states[:, : n_qk_nope_head_dim] = q_per_token_nope\n",
    "        query_states[:, n_qk_nope_head_dim :] = q_per_token_pe\n",
    "        \n",
    "        key_states = k_per_token_pe.new_empty(k_per_token_pe.shape[0], n_qk_nope_head_dim+n_qk_rope_head_dim)\n",
    "        key_states[:, : n_qk_nope_head_dim] = k_layer_head_nope\n",
    "        key_states[:, n_qk_nope_head_dim :] = k_per_token_pe\n",
    "        \n",
    "        qk_per_token = torch.matmul(query_states, key_states.T)/softmax_scale\n",
    "        \n",
    "        mask = torch.full((len(tokens), len(tokens)), float(\"-inf\"), device=tokens.device)\n",
    "        mask = torch.triu(mask, diagonal=1)\n",
    "        qk_per_token_after_masking = qk_per_token + mask\n",
    "        \n",
    "        qk_per_token_after_masking_after_softmax = torch.nn.functional.softmax(qk_per_token_after_masking, dim=1, dtype=torch.float32).to(torch.bfloat16)\n",
    "\n",
    "        qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)\n",
    "        \n",
    "        qkv_attention_store.append(qkv_attention)\n",
    "    \n",
    "    stacked_qkv_attention = torch.cat(qkv_attention_store, dim=-1)\n",
    "    w_layer = model[f\"model.layers.{layer}.self_attn.o_proj.weight\"]\n",
    "    embedding_delta = torch.matmul(stacked_qkv_attention, w_layer.T)\n",
    "    embedding_after_edit = final_embedding + embedding_delta\n",
    "    embedding_after_edit_normalized = rms_norm(embedding_after_edit, model[f\"model.layers.{layer}.post_attention_layernorm.weight\"])\n",
    "    \n",
    "    # shard exports\n",
    "    w1 = model[f\"model.layers.{layer}.mlp.shared_experts.gate_proj.weight\"]\n",
    "    w2 = model[f\"model.layers.{layer}.mlp.shared_experts.down_proj.weight\"]\n",
    "    w3 = model[f\"model.layers.{layer}.mlp.shared_experts.up_proj.weight\"]\n",
    "    output_after_shardexports = torch.matmul(torch.functional.F.silu(torch.matmul(embedding_after_edit_normalized, w1.T)) * torch.matmul(embedding_after_edit_normalized, w3.T), w2.T)\n",
    "\n",
    "    # route exports\n",
    "    # gate\n",
    "    gate_logits = torch.matmul(embedding_after_edit_normalized, model[f'model.layers.{layer}.mlp.gate.weight'].T)\n",
    "    gate_scores = gate_logits.softmax(dim=-1, dtype=torch.float32)\n",
    "    topk_weight, topk_idx = torch.topk(gate_scores, k=n_experts_per_tok, dim=-1, sorted=False)\n",
    "    # route\n",
    "    cnts = topk_idx.new_zeros((topk_idx.shape[0], n_routed_experts))\n",
    "    cnts.scatter_(1, topk_idx, 1)\n",
    "    tokens_per_expert = cnts.sum(dim=0)\n",
    "    idxs = topk_idx.view(-1).argsort()\n",
    "    sorted_tokens = embedding_after_edit_normalized[idxs // topk_idx.shape[1]]\n",
    "    tokens_per_expert = tokens_per_expert.cpu().numpy()\n",
    "    \n",
    "    outputs = []\n",
    "    start_idx = 0\n",
    "    for i, num_tokens in enumerate(tokens_per_expert):\n",
    "        end_idx = start_idx + num_tokens\n",
    "        if num_tokens == 0:\n",
    "            continue\n",
    "        w1 = model[f\"model.layers.{layer}.mlp.experts.{i}.gate_proj.weight\"]\n",
    "        w2 = model[f\"model.layers.{layer}.mlp.experts.{i}.down_proj.weight\"]\n",
    "        w3 = model[f\"model.layers.{layer}.mlp.experts.{i}.up_proj.weight\"]\n",
    "        tokens_for_this_expert = sorted_tokens[start_idx:end_idx]\n",
    "        expert_out = torch.matmul(torch.functional.F.silu(torch.matmul(tokens_for_this_expert, w1.T)) * torch.matmul(tokens_for_this_expert, w3.T), w2.T)\n",
    "        outputs.append(expert_out)\n",
    "        start_idx = end_idx\n",
    "\n",
    "    outs = torch.cat(outputs, dim=0) if len(outputs) else sorted_tokens.new_empty(0)\n",
    "    \n",
    "    new_x = torch.empty_like(outs)\n",
    "    new_x[idxs] = outs\n",
    "    output_after_routeexports = new_x.view(*topk_idx.shape, -1).type(topk_weight.dtype).mul_(topk_weight.unsqueeze(dim=-1)).sum(dim=1).type(new_x.dtype)\n",
    "    final_out = output_after_shardexports + output_after_routeexports\n",
    "    \n",
    "    final_embedding = embedding_after_edit + final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k v cache info\n",
    "# print(k_cache[0][0].shape)\n",
    "# print(k_cache[0][-1].shape)\n",
    "# print(len(k_cache))\n",
    "# print(len(k_cache[0]))\n",
    "# print(v_cache[0][0].shape)\n",
    "# print(v_cache[0][-1].shape)\n",
    "# print(len(v_cache))\n",
    "# print(len(v_cache[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we now have the final embedding, the best guess the model could make about the next token\n",
    "the shape of the embedding is the same as regular token embeddings [14x2048] where 14 is the number of tokens and 2048 is the embedding dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2048])"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embedding = rms_norm(final_embedding, model[\"model.norm.weight\"])\n",
    "final_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finally, lets decode the embedding into the token value\n",
    "we will use the output decoder to convert the final embedding into a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([102400, 2048])"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"lm_head.weight\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we use the embedding of the last token to predict the next value\n",
    "hopefully in our case: ninety "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([102400])"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.matmul(final_embedding[-1], model[\"lm_head.weight\"].T)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the model predicted token number 45351 as the next token, is this the token number for giants?\n",
    "IM HYPING YOU UP, this is the last cell of code, hopefully you had fun :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45351)"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token = torch.argmax(logits, dim=-1)\n",
    "next_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decode output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' giants'"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([next_token.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thank you, i love you :)\n",
    "This is the end. Hopefully you enjoyed reading it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
